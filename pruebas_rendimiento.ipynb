{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Librerias"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import rand,seed\n",
    "from matplotlib import pyplot as plt\n",
    "from time import time\n",
    "import pandas as pd\n",
    "from torchvision.datasets import MNIST"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T17:56:39.843771600Z",
     "start_time": "2024-01-12T17:56:36.984559Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Obteniendo el dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60.5%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\train-images-idx3-ubyte.gz to MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST\\raw\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST\\raw\\train-labels-idx1-ubyte.gz to MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST\\raw\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST\\raw\\t10k-images-idx3-ubyte.gz to MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n",
      "Extracting MNIST\\raw\\t10k-labels-idx1-ubyte.gz to MNIST\\raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_trainX, df_trainY = list(zip(*MNIST(root=\"\",\n",
    "                                       train=True,\n",
    "                                       download=True,\n",
    "                                       transform=np.asarray)))\n",
    "\n",
    "df_testX, df_testY = list(zip(*MNIST(root=\"\",\n",
    "                                       train=False,\n",
    "                                       download=True,\n",
    "                                       transform=np.asarray)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T17:56:42.878818100Z",
     "start_time": "2024-01-12T17:56:39.842775200Z"
    }
   },
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Funci√≥n de Entrenamiento"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train(n0, n1, v_fun, dv_fun, fun, grad, backtracking_fun,\n",
    "          trainy, trainx, testy, testx,\n",
    "          tam=None, noise=0.001, lam=0.001, toler=1e-3, beta=0.2,\n",
    "          gam=2, gradient=False, dibuja_ind=False):\n",
    "\n",
    "    # Tamao dataset\n",
    "    if tam is None:\n",
    "        select = np.where((trainy == n0) + (trainy == n1))[0]\n",
    "        tam = select.shape[0]\n",
    "    else:\n",
    "        select = np.where((trainy == n0) + (trainy == n1))[0][:tam]\n",
    "        \n",
    "    x_train = trainx[select].reshape(tam, 28 ** 2)  # /255.\n",
    "    x_train = (x_train - x_train.mean().astype(np.float32)) / x_train.std().astype(\n",
    "        np.float32)  # Image preprocessing: we standarized by substracting the mean and dividing by the standard deviation\n",
    "    select_test = np.where((testy == n0) + (testy == n1))[0]\n",
    "    x_test = testx[select_test].reshape(select_test.shape[0], 28 ** 2)  # /255.\n",
    "    x_test = (x_test - x_test.mean().astype(np.float32)) / x_test.std().astype(np.float32)\n",
    "\n",
    "    if noise is not None:\n",
    "        ruido = np.random.randn(*x_train.shape) * noise\n",
    "        smallest_sv = np.linalg.svd(x_train + ruido)[1].min()\n",
    "        if smallest_sv < 1e-6:\n",
    "            ruido = np.random.randn(*x_train.shape) * noise\n",
    "            smallest_sv = np.linalg.svd(x_train + ruido)[1].min()\n",
    "        x_train += ruido\n",
    "        x_test += np.random.randn(*x_test.shape) * noise\n",
    "        print('smallest singular value =', smallest_sv)\n",
    "    else:\n",
    "        smallest_sv = np.linalg.svd(x_train)[1].min()\n",
    "    x_train = np.concatenate([np.ones([x_train.shape[0], 1]), x_train], axis=1)\n",
    "    y_train = trainy[select] == n1\n",
    "    x_test = np.concatenate([np.ones([x_test.shape[0], 1]), x_test], axis=1)\n",
    "    y_test = testy[select_test] == n1\n",
    "\n",
    "    m = y_train.shape[0]\n",
    "    print('Numbers:', n0, 'and', n1)\n",
    "    print('m =', m)\n",
    "    print('noise =', noise)\n",
    "    print('lambda = ', lam)\n",
    "\n",
    "    y = 2 * y_train - 1\n",
    "    C = np.expand_dims(y, 1) * x_train.copy()\n",
    "    n = x_train.shape[1]\n",
    "\n",
    "    # cTx=(-4/3*lam+(16/9*lam**2+4*nc**4)**.5)/(2*nc**2)\n",
    "    # sol=3/4/lam*c*(1-cTx**2)\n",
    "\n",
    "    # def S2V(t, s):\n",
    "    #     if t < -1 or t > 1 or s == 0:\n",
    "    #         return 0\n",
    "    #     else:\n",
    "    #         return (3/2) * t * s\n",
    "\n",
    "    x0 = 2 * (rand(n) - .5)\n",
    "\n",
    "    x0 = 2 * (rand(n) - .5)\n",
    "    sol_alg1 = alg1(x0, sigma=0.2, t0=1, c=C, m=m, n=n, lam=lam, beta=beta, gam=gam, tol=toler)\n",
    "    print('Alg1 done! [n,m] = ', [n, m])\n",
    "    print('f(x0)= ', fun(x0, C, m))\n",
    "\n",
    "    print('Alg1 :', sol_alg1[1:])  # ,norm(sol-sol_alg1[0]))\n",
    "\n",
    "    y_train0 = (y_train == 0)\n",
    "    y_test0 = (y_test == 0)\n",
    "\n",
    "    aciertos_train = ((v_fun(x_train @ sol_alg1[0]) >= 0.5) == y_train0).sum()\n",
    "    aciertos_test = ((v_fun(x_test @ sol_alg1[0]) >= 0.5) == y_test0).sum()\n",
    "\n",
    "    print(\n",
    "        f'Aciertos en el conjunto de entrenamiento: {aciertos_train} de {y_train.shape[0]} ({(aciertos_train / y_train.shape[0]):2.2%})')\n",
    "    print(\n",
    "        f'Aciertos en el conjunto de test: {aciertos_test} de {y_test.shape[0]} ({(aciertos_test / y_test.shape[0]):2.2%})')\n",
    "\n",
    "    if dibuja_ind:\n",
    "        ind = np.where((v_fun(x_test @ sol_alg1[0]) >= 0.5) != y_test0)[0]\n",
    "        num_row, num_col = 2, int(np.ceil(ind.shape[0] / 2))\n",
    "        fig, axes = plt.subplots(num_row, num_col, figsize=(1.5 * num_col / 2, 2 * num_row / 2))\n",
    "        for i in range(ind.shape[0]):\n",
    "            ax = axes[i // num_col, i % num_col]\n",
    "            ax.imshow(x_test[ind[i]][1:].reshape(28, 28), cmap='gray_r')\n",
    "            ax.axis(False)\n",
    "            ax.set_title('Label: {} '.format(testy[select_test][ind[i]]), fontsize=10)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('Misclassified_' + str(n0) + '_' + str(n1) + '_' + str(tam) + '_' + str(noise) + '.pdf',\n",
    "                    bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "    if gradient:\n",
    "        sol_grad = grad(x0, tol=toler)\n",
    "        print('Grad done! [n,m] = ', [n, m])\n",
    "        print('Grad :', sol_grad[1:])  # ,norm(sol-sol_grad[0]))\n",
    "\n",
    "        aciertos_grad_train = ((v_fun(x_train @ sol_grad[0]) >= 0.5) == y_train0).sum()\n",
    "        aciertos_grad_test = ((v_fun(x_test @ sol_grad[0]) >= 0.5) == y_test0).sum()\n",
    "        print(\n",
    "            f'Aciertos en el conjunto de entrenamiento: {aciertos_grad_train} de {y_train.shape[0]} ({(aciertos_grad_train / y_train.shape[0]):2.2%})')\n",
    "        print(\n",
    "            f'Aciertos en el conjunto de test: {aciertos_grad_test} de {y_test.shape[0]} ({(aciertos_grad_test / y_test.shape[0]):2.2%})')\n",
    "        return smallest_sv, sol_alg1, y_train.shape[0], aciertos_train, y_test.shape[\n",
    "            0], aciertos_test, sol_grad, aciertos_grad_train, aciertos_grad_test\n",
    "    else:\n",
    "        return smallest_sv, sol_alg1, y_train.shape[0], aciertos_train, y_test.shape[0], aciertos_test"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.1 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2cf3f28c7a75e50c5c0ebcdf52430fdc4ff7d504b21f5c59b0c47c408c10bd3b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
