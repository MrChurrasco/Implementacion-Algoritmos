{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Librerias"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import rand,seed\n",
    "from numpy.linalg import norm,solve\n",
    "from matplotlib import pyplot as plt\n",
    "from time import time\n",
    "from keras.datasets import mnist\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T22:43:15.265641036Z",
     "start_time": "2024-01-04T22:43:15.263775230Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Set options"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',None)\n",
    "pd.set_option('display.max_rows',None)\n",
    "pd.set_option('display.width',300)\n",
    "\n",
    "seed(1)\n",
    "\n",
    "lam=0.001\n",
    "toler=1e-3\n",
    "# lam=0.005\n",
    "# m=6000\n",
    "\n",
    "# C=2*(rand(m,n)-.5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T22:43:16.860683032Z",
     "start_time": "2024-01-04T22:43:16.858424293Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Obteniendo el dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "(trainX,trainy),(testX,testy) = mnist.load_data()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T22:46:49.335581014Z",
     "start_time": "2024-01-04T22:46:49.197029767Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "(60000, 28, 28)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T22:46:02.093242776Z",
     "start_time": "2024-01-04T22:46:02.051924853Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T23:02:04.570635140Z",
     "start_time": "2024-01-04T22:57:48.532087078Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repet 1 of 10\n",
      "smallest singular value = 45.39161352441723\n",
      "Numbers: 1 and 7\n",
      "m = 13007\n",
      "noise = 0.5\n",
      "lambda =  0.001\n",
      "Alg1 done! [n,m] =  [785, 13007]\n",
      "f(x0)=  0.5443967249684162\n",
      "Alg1 : (862, 92.83107137680054, 0.002072513867355416, 0.000965414182640235)\n",
      "Aciertos en el conjunto de entrenamiento: 12987 de 13007 (99.85%)\n",
      "Aciertos en el conjunto de test: 2145 de 2163 (99.17%)\n",
      "Grad done! [n,m] =  [785, 13007]\n",
      "Grad : (4552, 151.28428864479065, 0.002012859735792381, 0.0016322814239045002)\n",
      "Aciertos en el conjunto de entrenamiento: 12988 de 13007 (99.85%)\n",
      "Aciertos en el conjunto de test: 2145 de 2163 (99.17%)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (1, 4) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[28], line 269\u001B[0m\n\u001B[1;32m    267\u001B[0m                 seed(r) \n\u001B[1;32m    268\u001B[0m                 R\u001B[38;5;241m.\u001B[39mappend([r,tam,noise,train(n0,n1,tam\u001B[38;5;241m=\u001B[39mtam,noise\u001B[38;5;241m=\u001B[39mnoise,gradient\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,toler\u001B[38;5;241m=\u001B[39mtolerancia)])\n\u001B[0;32m--> 269\u001B[0m                 \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msavez\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mResults_MNIST_noise_20231011\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43mR\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    270\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    271\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m np\u001B[38;5;241m.\u001B[39mload(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mResults_MNIST_noise_20231011.npz\u001B[39m\u001B[38;5;124m'\u001B[39m,allow_pickle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m datos:\n",
      "File \u001B[0;32m/media/sebastian/Otros/Practicas/Implementacion-Algoritmos/venv/lib/python3.11/site-packages/numpy/lib/npyio.py:639\u001B[0m, in \u001B[0;36msavez\u001B[0;34m(file, *args, **kwds)\u001B[0m\n\u001B[1;32m    555\u001B[0m \u001B[38;5;129m@array_function_dispatch\u001B[39m(_savez_dispatcher)\n\u001B[1;32m    556\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msavez\u001B[39m(file, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds):\n\u001B[1;32m    557\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Save several arrays into a single file in uncompressed ``.npz`` format.\u001B[39;00m\n\u001B[1;32m    558\u001B[0m \n\u001B[1;32m    559\u001B[0m \u001B[38;5;124;03m    Provide arrays as keyword arguments to store them under the\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    637\u001B[0m \n\u001B[1;32m    638\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 639\u001B[0m     \u001B[43m_savez\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/media/sebastian/Otros/Practicas/Implementacion-Algoritmos/venv/lib/python3.11/site-packages/numpy/lib/npyio.py:740\u001B[0m, in \u001B[0;36m_savez\u001B[0;34m(file, args, kwds, compress, allow_pickle, pickle_kwargs)\u001B[0m\n\u001B[1;32m    738\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key, val \u001B[38;5;129;01min\u001B[39;00m namedict\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m    739\u001B[0m     fname \u001B[38;5;241m=\u001B[39m key \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.npy\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m--> 740\u001B[0m     val \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43masanyarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43mval\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    741\u001B[0m     \u001B[38;5;66;03m# always force zip64, gh-10776\u001B[39;00m\n\u001B[1;32m    742\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m zipf\u001B[38;5;241m.\u001B[39mopen(fname, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m'\u001B[39m, force_zip64\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m fid:\n",
      "\u001B[0;31mValueError\u001B[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (1, 4) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "tam=5000\n",
    " \n",
    "n0=3\n",
    "n1=8\n",
    "\n",
    "noise=1e-3\n",
    "\n",
    "def dibuja(n0,n1,sol,noise=0.001):\n",
    "    select_test=np.where((testy==n0)+(testy==n1))[0]\n",
    "    x_test=testX[select_test].reshape(select_test.shape[0],28**2)#/255.\n",
    "    x_test=(x_test-x_test.mean().astype(np.float32))/x_test.std().astype(np.float32)\n",
    "    x_test+=np.random.randn(*x_test.shape)*noise\n",
    "    x_test=np.concatenate([np.ones([x_test.shape[0],1]),x_test],axis=1)\n",
    "    y_test=testy[select_test]==n1\n",
    "    y_test0=(y_test==0)\n",
    "    \n",
    "    def v(arr):\n",
    "        thresholds=(-1, 1)\n",
    "        funcs=(lambda t: 1, lambda t: 1/4*t**3-3/4*t+1/2, lambda t: 0)\n",
    "        masks = np.array([arr < threshold for threshold in thresholds])\n",
    "        masks = [masks[0]] + [x for x in masks[1:] & ~masks[:-1]] + [~masks[-1]]\n",
    "        result = np.empty_like(arr)\n",
    "        for mask, func in zip(masks, funcs):\n",
    "            result[mask] = func(arr[mask])\n",
    "        return result\n",
    "    \n",
    "    ind=np.where((v(x_test@sol)>=0.5)!=y_test0)[0]\n",
    "    num_row,num_col=2,int(np.ceil(ind.shape[0]/2))\n",
    "    fig, axes = plt.subplots(num_row, num_col, figsize=(1.5*num_col/2,2*num_row/2))\n",
    "    for i in range(ind.shape[0]):\n",
    "        ax = axes[i//num_col, i%num_col]\n",
    "        ax.imshow(x_test[ind[i]][1:].reshape(28,28), cmap='gray_r')\n",
    "        ax.axis(False)\n",
    "        ax.set_title('Label: {} '.format(testy[select_test][ind[i]]),fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig('Misclassified_'+str(n0)+'_'+str(n1)+'_'+str(tam)+'_'+str(noise)+'.pdf',bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def train(n0,n1,tam=None,noise=0.001,lam=0.001,toler=1e-3,beta=0.2,gam=2,gradient=False,dibuja=False):\n",
    "    if tam is None:\n",
    "        select=np.where((trainy==n0)+(trainy==n1))[0]\n",
    "    else:\n",
    "        select=np.where((trainy==n0)+(trainy==n1))[0][:tam]\n",
    "    tam=select.shape[0]\n",
    "    x_train=trainX[select].reshape(tam,28**2)#/255.\n",
    "    x_train=(x_train-x_train.mean().astype(np.float32))/x_train.std().astype(np.float32) #Image preprocessing: we standarized by substracting the mean and dividing by the standard deviation\n",
    "    select_test=np.where((testy==n0)+(testy==n1))[0]\n",
    "    x_test=testX[select_test].reshape(select_test.shape[0],28**2)#/255.\n",
    "    x_test=(x_test-x_test.mean().astype(np.float32))/x_test.std().astype(np.float32)\n",
    "\n",
    "    if noise is not None:\n",
    "        ruido=np.random.randn(*x_train.shape)*noise\n",
    "        smallest_sv=np.linalg.svd(x_train+ruido)[1].min()\n",
    "        if smallest_sv<1e-6:\n",
    "            ruido=np.random.randn(*x_train.shape)*noise\n",
    "            smallest_sv=np.linalg.svd(x_train+ruido)[1].min()\n",
    "        x_train+=ruido\n",
    "        x_test+=np.random.randn(*x_test.shape)*noise\n",
    "        print('smallest singular value =',smallest_sv)\n",
    "    else:\n",
    "        smallest_sv=np.linalg.svd(x_train)[1].min()    \n",
    "    x_train=np.concatenate([np.ones([x_train.shape[0],1]),x_train],axis=1)\n",
    "    y_train=trainy[select]==n1    \n",
    "    x_test=np.concatenate([np.ones([x_test.shape[0],1]),x_test],axis=1)\n",
    "    y_test=testy[select_test]==n1\n",
    "    \n",
    "    \n",
    "    m=y_train.shape[0]\n",
    "    print('Numbers:',n0,'and',n1)\n",
    "    print('m =',m)\n",
    "    print('noise =',noise)\n",
    "    print('lambda = ',lam)\n",
    "    \n",
    "    y=2*y_train-1\n",
    "    C=np.expand_dims(y,1)*x_train.copy()\n",
    "    n=x_train.shape[1]\n",
    "    \n",
    "    # cTx=(-4/3*lam+(16/9*lam**2+4*nc**4)**.5)/(2*nc**2)\n",
    "    # sol=3/4/lam*c*(1-cTx**2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def v(arr):\n",
    "        thresholds=(-1, 1)\n",
    "        funcs=(lambda t: 1, lambda t: 1/4*t**3-3/4*t+1/2, lambda t: 0)\n",
    "        # funcs=(lambda t: 1, lambda t: 1/2-0.5*np.sin(np.pi/2*t), lambda t: 0)\n",
    "        masks = np.array([arr < threshold for threshold in thresholds])\n",
    "        masks = [masks[0]] + [x for x in masks[1:] & ~masks[:-1]] + [~masks[-1]]\n",
    "        result = np.empty_like(arr)\n",
    "        for mask, func in zip(masks, funcs):\n",
    "            result[mask] = func(arr[mask])\n",
    "        return result\n",
    "    \n",
    "    def dv(arr):\n",
    "        thresholds=(-1, 1)\n",
    "        funcs=(lambda t: 0, lambda t: 3/4*t**2-3/4, lambda t: 0)\n",
    "        # funcs=(lambda t: 0, lambda t: -1/4*np.pi*np.cos(np.pi/2*t), lambda t: 0)\n",
    "        masks = np.array([arr < threshold for threshold in thresholds])\n",
    "        masks = [masks[0]] + [x for x in masks[1:] & ~masks[:-1]] + [~masks[-1]]\n",
    "        result = np.empty_like(arr)\n",
    "        for mask, func in zip(masks, funcs):\n",
    "            result[mask] = func(arr[mask])\n",
    "        return result\n",
    "    \n",
    "        \n",
    "    def backtracking(f,g,xk,pk,alpha=1,beta=0.5,c=1e-4):\n",
    "        rhs=c*g(xk)@pk\n",
    "        fxk=f(xk)\n",
    "        while f(xk+alpha*pk)>fxk+alpha*rhs:\n",
    "            alpha=beta*alpha\n",
    "        return alpha\n",
    "    \n",
    "    def f(x,Cx=None):\n",
    "        if Cx is None:\n",
    "            Cx=C@x\n",
    "        return 1/m*v(Cx).sum()+lam/2*norm(x)**2\n",
    "    \n",
    "    def df(x,Cx=None):\n",
    "        if Cx is None:\n",
    "            Cx=C@x\n",
    "        return 1/m*C.T@dv(Cx)+lam*x\n",
    "    \n",
    "    # def S2V(t, s):\n",
    "    #     if t < -1 or t > 1 or s == 0:\n",
    "    #         return 0\n",
    "    #     else:\n",
    "    #         return (3/2) * t * s\n",
    "    \n",
    "    def S2V(t, s):\n",
    "        # Ensure t and s are NumPy arrays of the same shape\n",
    "        # t = np.array(t)\n",
    "        # s = np.array(s)\n",
    "    \n",
    "        # Check conditions element-wise and compute the result element-wise\n",
    "        condition = (-1 <= t) & (t <= 1) & (s != 0)\n",
    "        result = np.where(condition, (3/2) * t * s, 0)\n",
    "        # result = np.where(condition, 1/8*np.pi**2*np.sin(np.pi/2*t) * s, 0)\n",
    "        return result\n",
    "    \n",
    "    def S2V2(t, s):\n",
    "        # Ensure t and s are NumPy arrays of the same shape\n",
    "        t = np.array(t)\n",
    "        s = np.array(s)\n",
    "    \n",
    "        # Check conditions element-wise and compute the result element-wise\n",
    "        condition = (-1 <= t) & (t <= 1) & (s != 0)\n",
    "        result=np.zeros_like(t)\n",
    "        result[condition]= (3/2) * t[condition] * s[condition]\n",
    "        return result\n",
    "    \n",
    "    \n",
    "    \n",
    "    x0=2*(rand(n)-.5)\n",
    "    \n",
    "    \n",
    "    def grad(x0,tol=1e-6):\n",
    "        t=time()\n",
    "        xk=x0.copy()\n",
    "        continua=True\n",
    "        k=0\n",
    "        while continua:\n",
    "            pk=-df(xk)\n",
    "            npk=norm(pk)\n",
    "            if npk<tol:\n",
    "                continua=False\n",
    "            paso=backtracking(f, df, xk, pk)\n",
    "            xk=xk+paso*pk\n",
    "            k+=1\n",
    "            # print(k,paso)\n",
    "            if paso<1e-14:\n",
    "                print(\"here\")\n",
    "        return xk,k,time()-t,f(xk),norm(df(xk))\n",
    "    \n",
    "    \n",
    "    def alg1(x0,sigma,t0,tol=1e-6,beta=0.5,gam=2):\n",
    "        t=time()\n",
    "        xk=x0.copy()\n",
    "        k=0\n",
    "        reduced=0\n",
    "        continua=True\n",
    "        tauk=t0\n",
    "        #CCT=C@C.T#np.expand_dims(c,1)@np.expand_dims(c,0)\n",
    "        nc2=np.linalg.norm(C.T, axis=0)**2\n",
    "        while continua:\n",
    "            Cxk=C@xk\n",
    "            wk=df(xk,Cxk)\n",
    "            if norm(wk)<tol:\n",
    "                continua=False\n",
    "            s=S2V(np.expand_dims(Cxk,1),np.ones((m, 1)))\n",
    "            s0=s.flatten()*nc2.flatten()\n",
    "            rhok=-np.sum(s0[s0 < 0])\n",
    "            # print(k,rhok)\n",
    "            dk=np.linalg.solve(C.T@(s*C)/m+(lam+rhok)*np.eye(n),-wk)\n",
    "            if reduced>=2:\n",
    "                tauk=gam*tauk\n",
    "            else:\n",
    "                reduced+=1\n",
    "            rhs=sigma*dk@wk\n",
    "            tauk=max(tauk,1e-6)\n",
    "            fxk=f(xk,Cxk)\n",
    "            while f(xk+tauk*dk)>fxk+tauk*rhs:\n",
    "                tauk=tauk*beta\n",
    "                reduced=0\n",
    "            xk=xk+tauk*dk\n",
    "            k+=1\n",
    "            # print(k,tauk,f(xk+tauk*dk),norm(wk))\n",
    "        return xk,k,time()-t,f(xk),norm(df(xk))\n",
    "            \n",
    "    x0=2*(rand(n)-.5)\n",
    "    sol_alg1=alg1(x0,sigma=0.2,t0=1,beta=beta,gam=gam,tol=toler)\n",
    "    print('Alg1 done! [n,m] = ', [n,m])\n",
    "    print('f(x0)= ',f(x0))\n",
    "    \n",
    "    print('Alg1 :',sol_alg1[1:])#,norm(sol-sol_alg1[0]))\n",
    "    \n",
    "    \n",
    "    y_train0=(y_train==0)\n",
    "    y_test0=(y_test==0)\n",
    "    \n",
    "    aciertos_train=((v(x_train@sol_alg1[0])>=0.5)==y_train0).sum()\n",
    "    aciertos_test=((v(x_test@sol_alg1[0])>=0.5)==y_test0).sum()\n",
    "    \n",
    "    print(f'Aciertos en el conjunto de entrenamiento: {aciertos_train} de {y_train.shape[0]} ({(aciertos_train/y_train.shape[0]):2.2%})')\n",
    "    print(f'Aciertos en el conjunto de test: {aciertos_test} de {y_test.shape[0]} ({(aciertos_test/y_test.shape[0]):2.2%})')\n",
    "    \n",
    "    if dibuja:\n",
    "        ind=np.where((v(x_test@sol_alg1[0])>=0.5)!=y_test0)[0]\n",
    "        num_row,num_col=2,int(np.ceil(ind.shape[0]/2))\n",
    "        fig, axes = plt.subplots(num_row, num_col, figsize=(1.5*num_col/2,2*num_row/2))\n",
    "        for i in range(ind.shape[0]):\n",
    "            ax = axes[i//num_col, i%num_col]\n",
    "            ax.imshow(x_test[ind[i]][1:].reshape(28,28), cmap='gray_r')\n",
    "            ax.axis(False)\n",
    "            ax.set_title('Label: {} '.format(testy[select_test][ind[i]]),fontsize=10)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('Misclassified_'+str(n0)+'_'+str(n1)+'_'+str(tam)+'_'+str(noise)+'.pdf',bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    if gradient:\n",
    "        sol_grad=grad(x0,tol=toler)\n",
    "        print('Grad done! [n,m] = ', [n,m])\n",
    "        print('Grad :',sol_grad[1:])#,norm(sol-sol_grad[0]))\n",
    "        \n",
    "        aciertos_grad_train=((v(x_train@sol_grad[0])>=0.5)==y_train0).sum()\n",
    "        aciertos_grad_test=((v(x_test@sol_grad[0])>=0.5)==y_test0).sum()\n",
    "        print(f'Aciertos en el conjunto de entrenamiento: {aciertos_grad_train} de {y_train.shape[0]} ({(aciertos_grad_train/y_train.shape[0]):2.2%})')\n",
    "        print(f'Aciertos en el conjunto de test: {aciertos_grad_test} de {y_test.shape[0]} ({(aciertos_grad_test/y_test.shape[0]):2.2%})')\n",
    "        return smallest_sv,sol_alg1,y_train.shape[0],aciertos_train,y_test.shape[0],aciertos_test,sol_grad,aciertos_grad_train,aciertos_grad_test\n",
    "    else:    \n",
    "        return smallest_sv,sol_alg1,y_train.shape[0],aciertos_train,y_test.shape[0],aciertos_test\n",
    "\n",
    "\n",
    "ejecuta_noise=True\n",
    "if ejecuta_noise:\n",
    "    tolerancia=1e-3\n",
    "    numeros=[1,7]\n",
    "    reps=10\n",
    "    ruido=[.5,1e-1,1e-2,1e-3,None]\n",
    "    tams=[None]\n",
    "    R=list()\n",
    "    n0=numeros[0]\n",
    "    n1=numeros[1]\n",
    "    for tam in tams:\n",
    "        for noise in ruido:\n",
    "            for r in range(reps):\n",
    "                print('repet',r+1,'of',reps)\n",
    "                seed(r) \n",
    "                R.append([r,tam,noise,train(n0,n1,tam=tam,noise=noise,gradient=True,toler=tolerancia)])\n",
    "                np.savez('Results_MNIST_noise_20231011',R)\n",
    "else:\n",
    "    with np.load('Results_MNIST_noise_20231011.npz',allow_pickle=True) as datos:\n",
    "        R=datos['arr_0']\n",
    "    S=([[R[k][3][2],R[k][2],R[k][3][2]-R[k][3][3],R[k][3][2]-R[k][3][7],R[k][3][4],R[k][3][4]-R[k][3][5],R[k][3][4]-R[k][3][8],round(R[k][3][5]/R[k][3][4]*100,2),round(100*R[k][3][8]/R[k][3][4],2),round(R[k][3][1][2],2),round(R[k][3][6][2],2),R[k][3][1][1],R[k][3][6][1]] for k in range(len(R))])\n",
    "    pdS=pd.DataFrame(S)\n",
    "    pdS.columns=['m','noise','f tr A1','f tr GD','test','f te A1','f te GD','%succ Alg1','%succ GD','time Alg1','time GD','it Alg1','it GD']\n",
    "    print(pdS)\n",
    "    print()\n",
    "\n",
    "if 0:\n",
    "    \n",
    "    ejecuta_noise2=True\n",
    "    if ejecuta_noise2:\n",
    "        tolerancia=1e-3\n",
    "        numeros=[[3,8],[8,9],[1,2],[5,6],[6,8],[4,9]]\n",
    "        reps=10\n",
    "        ruido=[1e-2,1e-3,None]\n",
    "        tams=[None]\n",
    "        R=list()\n",
    "        n0=numeros[0]\n",
    "        n1=numeros[1]\n",
    "        for tam in tams:\n",
    "            for noise in ruido:\n",
    "                for r in range(reps):\n",
    "                    print('repet',r+1,'of',reps)\n",
    "                    seed(r) \n",
    "                    R.append([r,tam,noise,train(n0,n1,tam=tam,noise=noise,gradient=True,toler=tolerancia)])\n",
    "                    np.savez('Results_MNIST_noise_20231011',R)\n",
    "    else:\n",
    "        with np.load('Results_MNIST_noise_20231011.npz',allow_pickle=True) as datos:\n",
    "            R=datos['arr_0']\n",
    "        S=([[R[k][3][2],R[k][2],R[k][3][2]-R[k][3][3],R[k][3][2]-R[k][3][7],R[k][3][4],R[k][3][4]-R[k][3][5],R[k][3][4]-R[k][3][8],round(R[k][3][5]/R[k][3][4]*100,2),round(100*R[k][3][8]/R[k][3][4],2),round(R[k][3][1][2],2),round(R[k][3][6][2],2),R[k][3][1][1],R[k][3][6][1]] for k in range(len(R))])\n",
    "        pdS=pd.DataFrame(S)\n",
    "        pdS.columns=['m','noise','f tr A1','f tr GD','test','f te A1','f te GD','%succ Alg1','%succ GD','time Alg1','time GD','it Alg1','it GD']\n",
    "        print(pdS)\n",
    "        print()\n",
    "    \n",
    "    \n",
    "            \n",
    "    if 1:\n",
    "        ejecuta=True\n",
    "        if ejecuta:\n",
    "            tolerancia=1e-3\n",
    "            numeros=[[1,7],[3,8],[8,9],[1,2],[5,6],[6,8],[4,9]]\n",
    "            ruido=[1e-2,1e-3,None]\n",
    "            tams=[100,500,1000,5000,None]\n",
    "            R=list()\n",
    "            for num in numeros:\n",
    "                n0=num[0]\n",
    "                n1=num[1]\n",
    "                for tam in tams:\n",
    "                    for noise in ruido:\n",
    "                        R.append([num,tam,noise,train(n0,n1,tam=tam,noise=noise,gradient=True,toler=tolerancia)])\n",
    "                        np.savez('Results_MNIST_1',R)\n",
    "        else:\n",
    "            with np.load('Results_MNIST_1.npz',allow_pickle=True) as datos:\n",
    "                R=datos['arr_0']\n",
    "            S=([[R[k][0][0],R[k][0][1],R[k][3][2],R[k][2],R[k][3][2]-R[k][3][3],R[k][3][2]-R[k][3][7],R[k][3][4],R[k][3][4]-R[k][3][5],R[k][3][4]-R[k][3][8],round(R[k][3][5]/R[k][3][4]*100,2),round(100*R[k][3][8]/R[k][3][4],2),round(R[k][3][1][2],2),round(R[k][3][6][2],2),R[k][3][1][1],R[k][3][6][1]] for k in range(len(R))])\n",
    "            pdS=pd.DataFrame(S)\n",
    "            pdS.columns=['n0','n1','m','noise','f tr A1','f tr GD','test','f te A1','f te GD','%succ Alg1','%succ GD','time Alg1','time GD','it Alg1','it GD']\n",
    "            print(pdS)\n",
    "            print()\n",
    "            print(pdS.loc[np.where(pdS.loc[:,'m']>5000)])\n",
    "            \n",
    "    if 1:\n",
    "        ejecuta=True\n",
    "        if ejecuta:\n",
    "            tolerancia=1e-3\n",
    "            numeros=[[3,8],[8,9],[1,2],[5,6],[6,8],[4,9]]\n",
    "            ruido=[1e-2,1e-3,None]\n",
    "            tams=[None]\n",
    "            R=list()\n",
    "            for num in numeros:\n",
    "                n0=num[0]\n",
    "                n1=num[1]\n",
    "                for tam in tams:\n",
    "                    for noise in ruido:\n",
    "                        R.append([num,tam,noise,train(n0,n1,tam=tam,noise=noise,gradient=True,toler=tolerancia)])\n",
    "                        np.savez('Results_MNIST_0',R)\n",
    "        else:\n",
    "            with np.load('Results_MNIST_0.npz',allow_pickle=True) as datos:\n",
    "                R=datos['arr_0']\n",
    "            S=([[R[k][0][0],R[k][0][1],R[k][3][2],R[k][2],R[k][3][2]-R[k][3][3],R[k][3][2]-R[k][3][7],R[k][3][4],R[k][3][4]-R[k][3][5],R[k][3][4]-R[k][3][8],round(R[k][3][5]/R[k][3][4]*100,2),round(100*R[k][3][8]/R[k][3][4],2),round(R[k][3][1][2],2),round(R[k][3][6][2],2),R[k][3][1][1],R[k][3][6][1]] for k in range(len(R))])\n",
    "            pdS=pd.DataFrame(S)\n",
    "            pdS.columns=['n0','n1','m','noise','f tr A1','f tr GD','test','f te A1','f te GD','%succ Alg1','%succ GD','time Alg1','time GD','it Alg1','it GD']\n",
    "            print(pdS)\n",
    "            print()\n",
    "            print(pdS.loc[np.where(pdS.loc[:,'m']>5000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.1 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2cf3f28c7a75e50c5c0ebcdf52430fdc4ff7d504b21f5c59b0c47c408c10bd3b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
